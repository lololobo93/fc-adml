{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes, cargamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ya saben, para gráficas pro\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer tarea, van a tener que programar la regresión logística. Completen de manera **sencilla** la función del descenso de gradiente. Yo les ayudo dándoles la función para encontrar un punto inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(c_inicial, costFunc, gradFunc, maxIter = 100, step = 0.01):\n",
    "    iteraciones = pd.DataFrame(columns = ['Costo','C'])\n",
    "    c = c_inicial\n",
    "    for i in range(0, maxIter):\n",
    "        costo = costFunc(c)\n",
    "        iteraciones.loc[iteraciones.shape[0]] = [costo, c]\n",
    "        # Ponga aquí el algoritmo del descenso\n",
    "    return c, iteraciones\n",
    "\n",
    "def randomSearch(costFunc, ranges, times = 60):\n",
    "    candidatos = pd.DataFrame(columns = ['Costo','C'])\n",
    "    for i in range(0,times):\n",
    "        rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "        candidato = np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]\n",
    "        costo = costFunc(candidato)\n",
    "        candidatos.loc[candidatos.shape[0]] = [costo, candidato]\n",
    "    return candidatos.sort_values(by = 'Costo',ascending = True).iloc[0].C, candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejercicio, definan las funciones \"parábola\" y \"parábolaGrad\" que calculen la función $f(\\vec{x}) = \\Vert \\vec{x} \\Vert^2$ quede minimizada, para un vector en r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parabola = lambda x: #Complete aquí\n",
    "parabolaGrad = lambda x: # Complete aquí\n",
    "\n",
    "\n",
    "#Búsqueda de un buen punto inicial\n",
    "# Nota: construya una matriz cuyo renglón tenga los rangos de búsqueda por variable\n",
    "ranges = # Complete\n",
    "c_inicial, candidatos = randomSearch(parabola, ranges)\n",
    " \n",
    "c, info = gradientDescent(c_inicial, parabola, parabolaGrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aquí, tenemos que el vector resultado es c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente bloque de código grafica todos los puntos de la búsqueda aleatoria (rojo), grafica la línea que siguió el descenso de gradiente (azul), y colorea en verde el óptimo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta cosa complicada convierte la columna de c's en una matrix en donde cada renglón es una c\n",
    "infoData = np.matrix( np.array(list(map(lambda x: np.array(x.T), list(info.C.values)))) )\n",
    "\n",
    "# Lo mismo pero para los \"candidatos\" de la búsqued aleatoria\n",
    "candidateData = np.matrix( np.array(list(map(lambda x: np.array(x.T), list(candidatos.C.values)))) )\n",
    "\n",
    "plt.plot(infoData[:,0], infoData[:,1], 'b')\n",
    "plt.plot(candidateData[:,0], candidateData[:,1],'ro')\n",
    "plt.plot(c[0],c[1], 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando las cosas para regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo visto hace dos clases, construya una función que calcule el gradiente de la función logística. Para ello necesitará una versión vectorial de la función sigmoide, propocionada aquí abajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = np.vectorize(# Ponga aquí dentro una lamnbda para calcular la sigmoide)\n",
    "\n",
    "plt.plot(np.linspace(-10,10,100), sigmoid(np.linspace(-10,10,100)), '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es crucial cargar los datos primero, pues nuestras definiciones de función de costo y de gradiente no pueden depender de las matrices X y Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLogDat = pd.read_csv(\"reglog.csv\")\n",
    "regLogDat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint_: use la función np.matrix para construir el vector columna Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = #COmplete\n",
    "Y = #Complete\n",
    "# Escriba aquí el costo de la regresión logística\n",
    "regLog = lambda theta: #Complete aquí\n",
    "# Escriba aquí el gradiente de la regresión logística\n",
    "def regLogGrad(theta):\n",
    "    # COmplete aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sugiera rangos apropiados de búsqueda para encontrar una c_inicialRL en dónde comenzar a hacer el descenso de graciente. Una vez hecho esto, ejectue el descenso de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Su código aquí\n",
    "rangesRL = #Complete\n",
    "c_inicialRL, candidatosRL = randomSearch(regLog,rangesRL)\n",
    "\n",
    "cRL, infoRL = gradientDescent(c_inicialRL, regLog, regLogGrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que la ecuación descrita por el producto interno de $\\vec{c}$ con cualquier vector $\\vec{x}$ es la siguiente:\n",
    "\n",
    "$$x_2 = -\\frac{c_1}{c_2} x_1 - \\frac{c_1 c_0}{c_2}$$\n",
    "\n",
    "Con esta información, definimos la ecuación de la recta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regLogRect(x):\n",
    "    coef = cRL.T.tolist()[0]\n",
    "    return -coef[1]/coef[2]*x - coef[1]*coef[0]/coef[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo se divide el espacio según esta recta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[(regLogDat.Color == 0),1], X[(regLogDat.Color == 0),2],'bo')\n",
    "plt.plot(X[(regLogDat.Color == 1),1], X[(regLogDat.Color == 1),2],'ro')\n",
    "plt.plot(np.linspace(0,1,2), regLogRect(np.linspace(0,1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # K - Vecinos más cercanos (principio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construya el modelo de k-vecinos más cercanos con la información que le ha sido proporcionada. Un ejercicio de tarea más complejo utilizará el resultado de este ejercicio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
