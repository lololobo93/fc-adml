{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea: Infinity War Pt.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este\n",
    "Primeramente hay que cargar librerías necesarias para la siguiente tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se generarán de manera aleatoria, siguiendo dos distribuciones _lognormal_ (como una normal chueca). Las \"Etiquetas\" de cada grupo de datos estarán ocultas en primer lugar, están dentro de la variable `labels`. Nos va a servir únicamente para verificar qué tan bien lo ha hecho el algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns = ['X1','X2','Color'])\n",
    "#Generado de la primer distribución\n",
    "for i in range(0,200):\n",
    "    data.loc[i] = [np.random.lognormal(2,0.4), np.random.lognormal(2,0.4), 0]\n",
    "#Generado de la segunda distribución\n",
    "for i in range(0,200):\n",
    "    data.loc[i+200] = [25 - np.random.lognormal(2,0.4), 25 - np.random.lognormal(2,0.4), 1]\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "labels = data.Color\n",
    "data = data.drop(columns = [\"Color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos dar un vistazo a los datos con la siguiente función. Es claro que hay \"Dos grupos\" pero queremos una manera exacta de separarlos, discriminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.X1, data.X2,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a escribir a manita el algoritmo de k-means clustering, pues es muy sencillo. Para ello habrá que rellenar campos de la siguiente función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansClusters(data, k = 2):\n",
    "    \"\"\"Calculates the k centroids to divide the data\"\"\"\n",
    "    #El siguiente argumento hace una matriz de \"Rangos\"\n",
    "    ranges = np.concatenate( (np.matrix(data.min().values),np.matrix(data.max().values)) ).T\n",
    "    #Con ella, se hace un vector aleatorio de las dimensiones de cada renglón de nuestros datos\n",
    "    rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "    #Se añade un centroide\n",
    "    centroids = (np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]).T\n",
    "    #Se añaden el resto de los centroides\n",
    "    for i in range(1,k):\n",
    "        rVec = np.matrix(np.random.random(ranges.shape[0])).T\n",
    "        centroids = np.concatenate((centroids,(np.multiply(ranges[:,1]-ranges[:,0],rVec) + ranges[:,0]).T))\n",
    "        \n",
    "    #Rellene la siguiente lambda para calcular el índice del centroide que más cerca esté a un renglón\n",
    "    # Bien podría ser la definición de una función, si no es suficiente\n",
    "    closest = lambda row:\n",
    "    changed = True;\n",
    "    while changed:\n",
    "        oldLabels = labels\n",
    "        #Aquí se calculan las distancias\n",
    "        labels = data.apply(closest, axis = 1)\n",
    "        \n",
    "        #Actualice aquí la posición de los \"centroides\"\n",
    "        #########################################\n",
    "        \n",
    "        #Actualice el valor de la variable \"changed\", debe ser false si los centroides no se movieron\n",
    "        changed = \n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ejecutamos el algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, predLabels = kMeansClusters(data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente bloque de código grafica los clusters en colores: Rojo un grupo, Azúl el otro, Verdes los puntos que están clasificados de manera incorrecta, cyan los centroides y ya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We swap the labels to to get the one with the highest percentage\n",
    "predLabels = np.logical_not(predLabels) if np.sum(predLabels == labels)/labels.shape[0] < 0.5 else predLabels\n",
    "#First we plot correct group 0 labels\n",
    "corrBlue = np.logical_and(labels == predLabels, labels == 0)\n",
    "plt.plot(data[corrBlue].X1, data[corrBlue].X2,'b.')\n",
    "plt.plot(centroids[0,0], centroids[0,1], 'co') #Cyan color\n",
    "#Second we plot correct group 1 labels\n",
    "corrRed = np.logical_and(labels == predLabels, labels == 1)\n",
    "plt.plot(data[corrRed].X1, data[corrRed].X2,'r.')\n",
    "plt.plot(centroids[1,0], centroids[1,1], 'co') #Cyan color\n",
    "#Third, we plot incorrect labels\n",
    "corrInc = labels != predLabels\n",
    "plt.plot(data[corrInc].X1, data[corrInc].X2,'g.')\n",
    "\n",
    "print(\"Porcentaje de clasificación: \", np.sum(predLabels == labels)/labels.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
